

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Reduction &mdash; tvm 0.7.dev1 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/img/tvm-logo-square.png"/>
  
  
  
  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/custom.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Scan and Recurrent Kernel" href="scan.html" />
    <link rel="prev" title="External Tensor Functions" href="extern_op.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    

<header class="header">
    <div class="innercontainer">
       <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
             <a href="../../index.html"><img src="https://raw.githubusercontent.com/tqchen/incubator-tvm-site/master/assets/images/logo.svg" alt="logo"></a>
          </div>
          <div id="headMenu" class="headerNav">
             <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href="https://tvm.apache.org/community">Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href="https://tvm.apache.org/download">Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href="https://tvm.apache.org/vta">VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href="https://tvm.apache.org/blog">Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href="">Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href="https://tvmconf.org/">Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href="https://github.com/apache/incubator-tvm/">Github</a>
                </li>
             </ul>
             <div class="responsiveasfdropdown">
                <button type="button" class="btn-link">
                ASF
                </button>
                <ul>
                   <li>
                      <a href="https://www.apache.org/">Apache Homepage</a>
                   </li>
                   <li>
                      <a href="https://www.apache.org/licenses/">License</a>
                   </li>
                   <li>
                      <a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a>
                   </li>
                   <li>
                      <a href="https://www.apache.org/security/">Security</a>
                   </li>
                   <li>
                      <a href="https://www.apache.org/foundation/thanks.html">Thanks</a>
                   </li>
                   <li>
                      <a href="https://apachecon.com/?ref=tvm.apache.org">Current Events</a>
                   </li>
                </ul>
             </div>
          </div>
          <div class="responsiveMenuIcon">
             <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
          </div>
          <div class="asfDropdown">
             <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                   <ul>
                      <li>
                         <a href="https://www.apache.org/">Apache Homepage</a>
                      </li>
                      <li>
                         <a href="https://www.apache.org/licenses/">License</a>
                      </li>
                      <li>
                         <a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a>
                      </li>
                      <li>
                         <a href="https://www.apache.org/security/">Security</a>
                      </li>
                      <li>
                         <a href="https://www.apache.org/foundation/thanks.html">Thanks</a>
                      </li>
                      <li>
                         <a href="https://apachecon.com/?ref=tvm.apache.org">Current Events</a>
                      </li>
                   </ul>
                </div>
             </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="sidetitle" alt="Documentation Home"> 0.7.dev1
          

          
          </a>

          
            
            
              <div class="version">
                0.7.dev1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">How to</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contribute to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Get Started Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#compile-deep-learning-models">Compile Deep Learning Models</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tedd.html">Use Tensor Expression Debug Display (TEDD) for Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="tuple_inputs.html">Compute and Reduce with Tuple Inputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="extern_op.html">External Tensor Functions</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Reduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#describe-sum-of-rows">Describe Sum of Rows</a></li>
<li class="toctree-l3"><a class="reference internal" href="#schedule-the-reduction">Schedule the Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reduction-factoring-and-parallelization">Reduction Factoring and Parallelization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cross-thread-reduction">Cross Thread Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#describe-convolution-via-2d-reduction">Describe Convolution via 2D Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#define-general-commutative-reduction-operation">Define General Commutative Reduction Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="scan.html">Scan and Recurrent Kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="intrin_math.html">Intrinsics and Math Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="schedule_primitives.html">Schedule Primitives in TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorize.html">Use Tensorize to Leverage Hardware Intrinsics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#autotvm-template-based-auto-tuning">AutoTVM : Template-based Auto Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#autoscheduler-template-free-auto-scheduling">AutoScheduler : Template-free Auto Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#micro-tvm">Micro TVM</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/links.html">Links to Other API References</a></li>
</ul>
<p class="caption"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Design and Architecture</a></li>
</ul>
<p class="caption"><span class="caption-text">MISC</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">
                
            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of content
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../index.html">Get Started Tutorials</a> <span class="br-arrow">></span></li>
        
      <li>Reduction</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/language/reduction.rst.txt" rel="nofollow"> <img src="../../_static/img/source.svg" alt="viewsource"/></a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-language-reduction-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="reduction">
<span id="sphx-glr-tutorials-language-reduction-py"></span><h1>Reduction<a class="headerlink" href="#reduction" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://tqchen.github.io">Tianqi Chen</a></p>
<p>This is an introduction material on how to do reduction in TVM.
Associative reduction operators like sum/max/min are typical
construction blocks of linear algebra operations.</p>
<p>In this tutorial, we will demonstrate how to do reduction in TVM.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">te</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
<div class="section" id="describe-sum-of-rows">
<h2>Describe Sum of Rows<a class="headerlink" href="#describe-sum-of-rows" title="Permalink to this headline">¶</a></h2>
<p>Assume we want to compute sum of rows as our example.
In numpy semantics this can be written as <code class="code docutils literal notranslate"><span class="pre">B</span> <span class="pre">=</span> <span class="pre">numpy.sum(A,</span> <span class="pre">axis=1)</span></code></p>
<p>The following lines describe the row sum operation.
To create a reduction formula, we declare a reduction axis using
<a class="reference internal" href="../../api/python/te.html#tvm.te.reduce_axis" title="tvm.te.reduce_axis"><code class="xref any py py-func docutils literal notranslate"><span class="pre">te.reduce_axis</span></code></a>. <a class="reference internal" href="../../api/python/te.html#tvm.te.reduce_axis" title="tvm.te.reduce_axis"><code class="xref any py py-func docutils literal notranslate"><span class="pre">te.reduce_axis</span></code></a> takes in the range of reductions.
<a class="reference internal" href="../../api/python/te.html#tvm.te.sum" title="tvm.te.sum"><code class="xref any py py-func docutils literal notranslate"><span class="pre">te.sum</span></code></a> takes in the expression to be reduced as well as the reduction
axis and compute the sum of value over all k in the declared range.</p>
<p>The equivalent C code is as follows:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">m</span><span class="p">;</span> <span class="o">++</span><span class="n">k</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">];</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><span class="n">te</span><span class="o">.</span><span class="n">var</span></a></a></a><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><span class="n">te</span><span class="o">.</span><span class="n">var</span></a></a></a><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a></a></a><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;A&quot;</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span></a></a></a><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><span class="n">te</span><span class="o">.</span><span class="n">compute</span></a></a></a><span class="p">((</span><span class="n">n</span><span class="p">,),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <a href="../../api/python/te.html#tvm.te.sum" title="View documentation for tvm.te.sum"><a href="../../api/python/te.html#tvm.te.sum" title="View documentation for tvm.te.sum"><a href="../../api/python/te.html#tvm.te.sum" title="View documentation for tvm.te.sum"><span class="n">te</span><span class="o">.</span><span class="n">sum</span></a></a></a><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="schedule-the-reduction">
<h2>Schedule the Reduction<a class="headerlink" href="#schedule-the-reduction" title="Permalink to this headline">¶</a></h2>
<p>There are several ways to schedule a reduction.
Before doing anything, let us print out the IR code of default schedule.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><span class="n">te</span><span class="o">.</span><span class="n">create_schedule</span></a></a></a><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><span class="n">tvm</span><span class="o">.</span><span class="n">lower</span></a></a></a><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="n">simple_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<p>You can find that the IR code is quite like the C code.
The reduction axis is similar to a normal axis, it can be splitted.</p>
<p>In the following code we split both the row axis of B as well
axis by different factors. The result is a nested reduction.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ko</span><span class="p">,</span> <span class="n">ki</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">factor</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">xo</span><span class="p">,</span> <span class="n">xi</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">factor</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><span class="n">tvm</span><span class="o">.</span><span class="n">lower</span></a></a></a><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="n">simple_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<p>If we are building a GPU kernel, we can bind the rows of B to GPU threads.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">xo</span><span class="p">,</span> <a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><span class="n">te</span><span class="o">.</span><span class="n">thread_axis</span></a></a></a><span class="p">(</span><span class="s2">&quot;blockIdx.x&quot;</span><span class="p">))</span>
<span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><span class="n">te</span><span class="o">.</span><span class="n">thread_axis</span></a></a></a><span class="p">(</span><span class="s2">&quot;threadIdx.x&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><span class="n">tvm</span><span class="o">.</span><span class="n">lower</span></a></a></a><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="n">simple_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="reduction-factoring-and-parallelization">
<h2>Reduction Factoring and Parallelization<a class="headerlink" href="#reduction-factoring-and-parallelization" title="Permalink to this headline">¶</a></h2>
<p>One problem of building a reduction is that we cannot simply
parallelize over the reduction axis. We need to divide the computation
of the reduction, store the local reduction result in a temporal array
before doing a reduction over the temp array.</p>
<p>The rfactor primitive does such rewrite of the computation.
In the following schedule, the result of B is written to a temporary
result B.rf. The factored dimension becomes the first dimension of B.rf.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><span class="n">te</span><span class="o">.</span><span class="n">create_schedule</span></a></a></a><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
<span class="n">ko</span><span class="p">,</span> <span class="n">ki</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">factor</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">BF</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">rfactor</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">ki</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><span class="n">tvm</span><span class="o">.</span><span class="n">lower</span></a></a></a><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="n">simple_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<p>The scheduled operator of B also get rewritten to be sum over
the first axis of reduced result of B.f</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="cross-thread-reduction">
<h2>Cross Thread Reduction<a class="headerlink" href="#cross-thread-reduction" title="Permalink to this headline">¶</a></h2>
<p>We can now parallelize over the factored axis.
Here the reduction axis of B is marked to be a thread.
TVM allows reduction axis to be marked as thread if it is the only
axis in reduction and cross thread reduction is possible in the device.</p>
<p>This is indeed the case after the factoring.
We can directly compute BF at the reduction axis as well.
The final generated kernel will divide the rows by blockIdx.x and threadIdx.y
columns by threadIdx.x and finally do a cross thread reduction over threadIdx.x</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xo</span><span class="p">,</span> <span class="n">xi</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">factor</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">xo</span><span class="p">,</span> <a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><span class="n">te</span><span class="o">.</span><span class="n">thread_axis</span></a></a></a><span class="p">(</span><span class="s2">&quot;blockIdx.x&quot;</span><span class="p">))</span>
<span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><span class="n">te</span><span class="o">.</span><span class="n">thread_axis</span></a></a></a><span class="p">(</span><span class="s2">&quot;threadIdx.y&quot;</span><span class="p">))</span>
<span class="n">tx</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><a href="../../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><span class="n">te</span><span class="o">.</span><span class="n">thread_axis</span></a></a></a><span class="p">(</span><span class="s2">&quot;threadIdx.x&quot;</span><span class="p">)</span>
<span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tx</span><span class="p">)</span>
<span class="n">s</span><span class="p">[</span><span class="n">BF</span><span class="p">]</span><span class="o">.</span><span class="n">compute_at</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">set_store_predicate</span><span class="p">(</span><span class="n">tx</span><span class="o">.</span><span class="n">var</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="n">fcuda</span> <span class="o">=</span> <a href="../../api/python/driver.html#tvm.build" title="View documentation for tvm.build"><a href="../../api/python/driver.html#tvm.build" title="View documentation for tvm.build"><a href="../../api/python/driver.html#tvm.build" title="View documentation for tvm.build"><span class="n">tvm</span><span class="o">.</span><span class="n">build</span></a></a></a><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fcuda</span><span class="o">.</span><span class="n">imported_modules</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_source</span><span class="p">())</span>
</pre></div>
</div>
<p>Verify the correctness of result kernel by comparing it to numpy.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a></a></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html#numpy.random.uniform" title="View documentation for numpy.random.uniform"><a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html#numpy.random.uniform" title="View documentation for numpy.random.uniform"><a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html#numpy.random.uniform" title="View documentation for numpy.random.uniform"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span></a></a></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">nn</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a></a></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="View documentation for numpy.zeros"><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="View documentation for numpy.zeros"><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="View documentation for numpy.zeros"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a></a></a><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">B</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">fcuda</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">tvm</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="View documentation for numpy.sum"><a href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="View documentation for numpy.sum"><a href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="View documentation for numpy.sum"><span class="n">np</span><span class="o">.</span><span class="n">sum</span></a></a></a><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="describe-convolution-via-2d-reduction">
<h2>Describe Convolution via 2D Reduction<a class="headerlink" href="#describe-convolution-via-2d-reduction" title="Permalink to this headline">¶</a></h2>
<p>In TVM, we can describe convolution via 2D reduction in a simple way.
Here is an example for 2D convolution with filter size = [3, 3] and strides = [1, 1].</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><span class="n">te</span><span class="o">.</span><span class="n">var</span></a></a></a><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">)</span>
<span class="n">Input</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a></a></a><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Input&quot;</span><span class="p">)</span>
<span class="n">Filter</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a></a></a><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Filter&quot;</span><span class="p">)</span>
<span class="n">di</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span></a></a></a><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;di&quot;</span><span class="p">)</span>
<span class="n">dj</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span></a></a></a><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;dj&quot;</span><span class="p">)</span>
<span class="n">Output</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><span class="n">te</span><span class="o">.</span><span class="n">compute</span></a></a></a><span class="p">(</span>
    <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">),</span>
    <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <a href="../../api/python/te.html#tvm.te.sum" title="View documentation for tvm.te.sum"><a href="../../api/python/te.html#tvm.te.sum" title="View documentation for tvm.te.sum"><a href="../../api/python/te.html#tvm.te.sum" title="View documentation for tvm.te.sum"><span class="n">te</span><span class="o">.</span><span class="n">sum</span></a></a></a><span class="p">(</span><span class="n">Input</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">di</span><span class="p">,</span> <span class="n">j</span> <span class="o">+</span> <span class="n">dj</span><span class="p">]</span> <span class="o">*</span> <span class="n">Filter</span><span class="p">[</span><span class="n">di</span><span class="p">,</span> <span class="n">dj</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">di</span><span class="p">,</span> <span class="n">dj</span><span class="p">]),</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Output&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><span class="n">te</span><span class="o">.</span><span class="n">create_schedule</span></a></a></a><span class="p">(</span><span class="n">Output</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><span class="n">tvm</span><span class="o">.</span><span class="n">lower</span></a></a></a><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">Input</span><span class="p">,</span> <span class="n">Filter</span><span class="p">,</span> <span class="n">Output</span><span class="p">],</span> <span class="n">simple_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="define-general-commutative-reduction-operation">
<span id="general-reduction"></span><h2>Define General Commutative Reduction Operation<a class="headerlink" href="#define-general-commutative-reduction-operation" title="Permalink to this headline">¶</a></h2>
<p>Besides the built-in reduction operations like <a class="reference internal" href="../../api/python/te.html#tvm.te.sum" title="tvm.te.sum"><code class="xref any py py-func docutils literal notranslate"><span class="pre">te.sum</span></code></a>,
<a class="reference internal" href="../../api/python/te.html#tvm.te.min" title="tvm.te.min"><code class="xref any py py-func docutils literal notranslate"><span class="pre">tvm.te.min</span></code></a> and <a class="reference internal" href="../../api/python/te.html#tvm.te.max" title="tvm.te.max"><code class="xref any py py-func docutils literal notranslate"><span class="pre">tvm.te.max</span></code></a>, you can also define your
commutative reduction operation by <a class="reference internal" href="../../api/python/te.html#tvm.te.comm_reducer" title="tvm.te.comm_reducer"><code class="xref any py py-func docutils literal notranslate"><span class="pre">te.comm_reducer</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><span class="n">te</span><span class="o">.</span><span class="n">var</span></a></a></a><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><a href="../../api/python/te.html#tvm.te.var" title="View documentation for tvm.te.var"><span class="n">te</span><span class="o">.</span><span class="n">var</span></a></a></a><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">)</span>
<span class="n">product</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.comm_reducer" title="View documentation for tvm.te.comm_reducer"><a href="../../api/python/te.html#tvm.te.comm_reducer" title="View documentation for tvm.te.comm_reducer"><a href="../../api/python/te.html#tvm.te.comm_reducer" title="View documentation for tvm.te.comm_reducer"><span class="n">te</span><span class="o">.</span><span class="n">comm_reducer</span></a></a></a><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">tir</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">t</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;product&quot;</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a></a></a><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;A&quot;</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span></a></a></a><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><span class="n">te</span><span class="o">.</span><span class="n">compute</span></a></a></a><span class="p">((</span><span class="n">n</span><span class="p">,),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">product</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sometimes we would like to perform reduction that involves multiple
values like <code class="code docutils literal notranslate"><span class="pre">argmax</span></code>, which can be done by tuple inputs.
See <a class="reference internal" href="tuple_inputs.html#reduction-with-tuple-inputs"><span class="std std-ref">Describe Reduction with Collaborative Inputs</span></a> for more detail.</p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>This tutorial provides a walk through of reduction schedule.</p>
<ul class="simple">
<li><p>Describe reduction with reduce_axis.</p></li>
<li><p>Use rfactor to factor out axis if we need parallelism.</p></li>
<li><p>Define new reduction operation by <a class="reference internal" href="../../api/python/te.html#tvm.te.comm_reducer" title="tvm.te.comm_reducer"><code class="xref any py py-func docutils literal notranslate"><span class="pre">te.comm_reducer</span></code></a></p></li>
</ul>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-language-reduction-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/5bd1bb9c6505ea40407fa19f01579414/reduction.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">reduction.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ea430ddc44893f3ac69585718b79c09c/reduction.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">reduction.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="scan.html" class="btn btn-neutral float-right" title="Scan and Recurrent Kernel" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="extern_op.html" class="btn btn-neutral float-left" title="External Tensor Functions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <ul class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <li class="copywrite d-flex align-items-center">
          <h5 id="apache-software-foundation--all-right-reserved">© 2020 Apache Software Foundation | All right reserved</h5>
        </li>
      </ul>
  
    </div>
  
    <ul>
      <li class="footernote">Apache TVM is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF. Copyright © 2020 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</li>
    </ul>
  
</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
    
  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>